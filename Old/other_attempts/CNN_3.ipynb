{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')  # Or any other X11 back-end   \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import signal\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import wfdb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepDatasetValid(Dataset):\n",
    "    \"\"\"Physionet 2018 dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, records_file, root_dir, s, f, window_size, hanning_window):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            records_file (string): Path to the records file.\n",
    "            root_dir (string): Directory with all the signals.\n",
    "\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(records_file)[s:f]\n",
    "        self.root_dir = root_dir\n",
    "        self.window_size = window_size\n",
    "        self.hw = hanning_window\n",
    "        self.num_bins = window_size//hanning_window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        file_name = self.landmarks_frame.iloc[idx, 0]\n",
    "#         print(file_name)\n",
    "#         print(folder_name)\n",
    "#         file_name='tr03-0005/'\n",
    "#         folder_name='../data/training/tr03-0005/'\n",
    "        signals = wfdb.rdrecord(os.path.join(folder_name, file_name[:-1]))\n",
    "        arousals = h5py.File(os.path.join(folder_name, file_name[:-1] + '-arousal.mat'), 'r')\n",
    "        tst_ann = wfdb.rdann(os.path.join(folder_name, file_name[:-1]), 'arousal')\n",
    "        \n",
    "        positive_indexes = []\n",
    "        negative_indexes = []\n",
    "        \n",
    "        arous_data = arousals['data']['arousals'].value.ravel()\n",
    "        \n",
    "        for w in range(len(arous_data)//self.window_size):\n",
    "            if arous_data[w*self.window_size:(w+1)*self.window_size].max() > 0:\n",
    "                positive_indexes.append(w)\n",
    "            else:\n",
    "                negative_indexes.append(w)\n",
    "        \n",
    "#             max_in_window = arous_data[].max()\n",
    "        if len(positive_indexes) < len(negative_indexes):\n",
    "            windexes = np.append(positive_indexes, np.random.choice(negative_indexes, len(positive_indexes)//10, replace=False))\n",
    "        else:\n",
    "            windexes = np.append(negative_indexes, np.random.choice(positive_indexes, len(negative_indexes), replace=False))\n",
    "        windexes = np.sort(windexes)\n",
    "        \n",
    "        labels = []\n",
    "        total = 0\n",
    "        positive = 0\n",
    "        for i in windexes:\n",
    "            tmp = []\n",
    "            window_s = i*self.window_size\n",
    "            window_e = (i+1)*self.window_size\n",
    "            for j in range(self.num_bins):\n",
    "                total += 1\n",
    "                bin_s = j*self.hw + window_s\n",
    "                bin_e = (j+1)*self.hw + window_s\n",
    "                if arous_data[bin_s:bin_e].max() > 0:\n",
    "                    tmp.append(1)\n",
    "                    positive += 1\n",
    "                else:\n",
    "                    tmp.append(0)\n",
    "            labels.append(tmp)\n",
    "#         print('sample percent ratio: {:.2f}'.format(positive/total))\n",
    "        interested = [0]\n",
    "#         for i in range(13):\n",
    "#             if signals.sig_name[i] in ['SaO2', 'ABD', 'F4-M1', 'C4-M1', 'O2-M1', 'AIRFLOW']:\n",
    "#             interested.append(i)\n",
    "#         POI = arousal_centers\n",
    "        sample =  ((signals.p_signal[:,interested], windexes), arous_data)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepDataset(Dataset):\n",
    "    \"\"\"Physionet 2018 dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, records_file, root_dir, s, f, window_size, hanning_window, validation=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            records_file (string): Path to the records file.\n",
    "            root_dir (string): Directory with all the signals.\n",
    "\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(records_file)[s:f]\n",
    "        self.root_dir = root_dir\n",
    "        self.window_size = window_size\n",
    "        self.hw = hanning_window\n",
    "        self.num_bins = window_size//hanning_window\n",
    "        \n",
    "        self.validation=validation\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        np.random.seed(12345)\n",
    "        folder_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        file_name = self.landmarks_frame.iloc[idx, 0]\n",
    "#         print(file_name)\n",
    "#         print(folder_name)\n",
    "#         file_name='tr03-0005/'\n",
    "#         folder_name='../data/training/tr03-0005/'\n",
    "        signals = wfdb.rdrecord(os.path.join(folder_name, file_name[:-1]))\n",
    "        arousals = h5py.File(os.path.join(folder_name, file_name[:-1] + '-arousal.mat'), 'r')\n",
    "        tst_ann = wfdb.rdann(os.path.join(folder_name, file_name[:-1]), 'arousal')\n",
    "        \n",
    "        positive_indexes = []\n",
    "        negative_indexes = []\n",
    "        \n",
    "        arous_data = arousals['data']['arousals'].value.ravel()\n",
    "        \n",
    "        for w in range(len(arous_data)//self.window_size):\n",
    "            if arous_data[w*self.window_size:(w+1)*self.window_size].max() > 0:\n",
    "                positive_indexes.append(w)\n",
    "            else:\n",
    "                negative_indexes.append(w)\n",
    "        \n",
    "#             max_in_window = arous_data[].max()\n",
    "        \n",
    "        if self.validation:\n",
    "            windexes = np.append(positive_indexes, negative_indexes)\n",
    "        else: \n",
    "            if len(positive_indexes) < len(negative_indexes):\n",
    "                windexes = np.append(positive_indexes, np.random.choice(negative_indexes, len(positive_indexes)//10, replace=False))\n",
    "            else:\n",
    "                windexes = np.append(negative_indexes, np.random.choice(positive_indexes, len(negative_indexes), replace=False))\n",
    "            windexes = np.sort(windexes)\n",
    "#         windexes = np.array(positive_indexes)\n",
    "        labels = []\n",
    "        total = 0\n",
    "        positive = 0\n",
    "        for i in windexes:\n",
    "            tmp = []\n",
    "            window_s = i*self.window_size\n",
    "            window_e = (i+1)*self.window_size\n",
    "            for j in range(self.num_bins):\n",
    "                total += 1\n",
    "                bin_s = j*self.hw + window_s\n",
    "                bin_e = (j+1)*self.hw + window_s\n",
    "                if arous_data[bin_s:bin_e].max() > 0:\n",
    "                    positive += 1\n",
    "                    tmp.append(1.)\n",
    "                else:\n",
    "                    tmp.append(0.)\n",
    "            labels.append(tmp)\n",
    "        \n",
    "        interested = []\n",
    "#         print('# sample positive: {:.2f} #'.format(positive/total))\n",
    "        for i in range(13):\n",
    "#             if signals.sig_name[i] in ['SaO2', 'ABD', 'F4-M1', 'C4-M1', 'O2-M1', 'AIRFLOW']:\n",
    "            interested.append(i)\n",
    "#         POI = arousal_centers\n",
    "#         tst_sig = np.random.rand(len(signals.p_signal[:,interested]),1)\n",
    "        sample =  ((signals.p_signal[:,interested], windexes), np.array(labels))\n",
    "#         sample =  ((tst_sig, windexes), np.array(labels))\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_V3(nn.Module):\n",
    "\n",
    "    def __init__(self, window_size, han_size):\n",
    "        super(Model_V3, self).__init__()\n",
    "        num_bins = window_size//han_size\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(13, num_bins, 3, padding=1)\n",
    "        init.xavier_uniform(self.cnn1.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        init.constant(self.cnn1.bias, 0.1)\n",
    "        self.cnn2 = nn.Conv2d(4, 8, 3, padding=1)\n",
    "        init.xavier_uniform(self.cnn2.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        init.constant(self.cnn2.bias, 0.1)\n",
    "#         self.cnn3 = nn.Conv2d(32, num_bins, 3, padding=1)\n",
    "        self.cnn3 = nn.Conv2d(8, num_bins, 3, padding=1)\n",
    "        init.xavier_uniform(self.cnn3.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        init.constant(self.cnn3.bias, 0.1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "#         out_dim = ((han_size//2+1)//8)*((window_size//han_size)//8)*16\n",
    "        self.output = nn.AdaptiveMaxPool2d(1)\n",
    "#         self.fc = nn.Linear(out_dim, num_bins)\n",
    "        self.fc = nn.Linear(num_bins, num_bins)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.do = nn.Dropout()\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.pool(self.cnn1(x)))\n",
    "\n",
    "#         x = self.relu(self.pool(self.cnn2(x)))\n",
    "#         x = self.relu(self.pool(self.cnn3(x)))\n",
    "\n",
    "        x = self.output(x)\n",
    "        x = self.fc(x.view(-1))\n",
    "        x = self.sigmoid(x)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjusted window size: 24576, num bins: 12\n",
      "FC # params: 36864\n"
     ]
    }
   ],
   "source": [
    "minutes = 2\n",
    "raw_window_size = minutes*60*200\n",
    "hanning_window = 2048\n",
    "window_size = raw_window_size + (hanning_window - (raw_window_size + hanning_window) % hanning_window)\n",
    "print('adjusted window size: {}, num bins: {}'.format(window_size, window_size//hanning_window))\n",
    "output_pixels = ((window_size//hanning_window * (hanning_window//2+1))//64)*16\n",
    "print('FC # params: {}'.format(output_pixels*window_size//hanning_window))\n",
    "learning_rate = 1e-3\n",
    "\n",
    "def to_spectogram(matrix):\n",
    "    spectograms = []\n",
    "    for i in range(all_data.size()[2]):\n",
    "        f, t, Sxx = signal.spectrogram(matrix[0,:,i].numpy(), \n",
    "                           window=signal.get_window('hann',hanning_window, False), \n",
    "                           fs=200, \n",
    "                           scaling='density', \n",
    "                           mode='magnitude',\n",
    "                           noverlap=0\n",
    "                          )\n",
    "        if (Sxx.min() != 0 or Sxx.max() != 0):\n",
    "            spectograms.append((Sxx - Sxx.mean()) / Sxx.std())\n",
    "        else:\n",
    "            spectograms.append(Sxx)\n",
    "    return torch.FloatTensor(spectograms).unsqueeze(0).cuda()\n",
    "\n",
    "#TODO add torch.save(the_model.state_dict(), PATH) this to save the best models weights\n",
    "\n",
    "train_dataset = SleepDataset('/beegfs/ga4493/projects/groupb/data/training/RECORDS', \n",
    "                             '/beegfs/ga4493/projects/groupb/data/training/', 20, 21, window_size, hanning_window)\n",
    "\n",
    "train_loaders = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = SleepDataset('/beegfs/ga4493/projects/groupb/data/training/RECORDS', \n",
    "                                '/beegfs/ga4493/projects/groupb/data/training/', 0, 1, window_size, hanning_window, validation=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=1, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "#############################################\n",
      "# epoch  -          0 | time(s) -      8.31 #\n",
      "# T loss -      41.48 | V loss -      16.60 #\n",
      "# T acc  -       0.58 | V acc  -       0.51 #\n",
      "#############################################\n",
      "# epoch  -          1 | time(s) -      8.92 #\n",
      "# T loss -      13.41 | V loss -      15.05 #\n",
      "# T acc  -       0.63 | V acc  -       0.53 #\n",
      "#############################################\n",
      "# epoch  -          2 | time(s) -      8.94 #\n",
      "# T loss -      11.08 | V loss -      14.52 #\n",
      "# T acc  -       0.64 | V acc  -       0.52 #\n",
      "#############################################\n",
      "# epoch  -          3 | time(s) -      8.86 #\n",
      "# T loss -       9.87 | V loss -      14.13 #\n",
      "# T acc  -       0.65 | V acc  -       0.53 #\n",
      "#############################################\n",
      "# epoch  -          4 | time(s) -      8.88 #\n",
      "# T loss -       8.96 | V loss -      13.80 #\n",
      "# T acc  -       0.67 | V acc  -       0.54 #\n",
      "#############################################\n",
      "# epoch  -          5 | time(s) -      8.87 #\n",
      "# T loss -       8.31 | V loss -      13.65 #\n",
      "# T acc  -       0.69 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -          6 | time(s) -      9.15 #\n",
      "# T loss -       7.78 | V loss -      13.41 #\n",
      "# T acc  -       0.70 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -          7 | time(s) -      9.02 #\n",
      "# T loss -       7.31 | V loss -      13.31 #\n",
      "# T acc  -       0.72 | V acc  -       0.54 #\n",
      "#############################################\n",
      "# epoch  -          8 | time(s) -      9.06 #\n",
      "# T loss -       6.86 | V loss -      12.88 #\n",
      "# T acc  -       0.73 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -          9 | time(s) -      9.19 #\n",
      "# T loss -       6.47 | V loss -      12.33 #\n",
      "# T acc  -       0.75 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -         10 | time(s) -      9.02 #\n",
      "# T loss -       6.10 | V loss -      12.13 #\n",
      "# T acc  -       0.76 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -         11 | time(s) -      9.13 #\n",
      "# T loss -       5.85 | V loss -      12.05 #\n",
      "# T acc  -       0.78 | V acc  -       0.54 #\n",
      "#############################################\n",
      "# epoch  -         12 | time(s) -      9.16 #\n",
      "# T loss -       5.58 | V loss -      12.00 #\n",
      "# T acc  -       0.80 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -         13 | time(s) -      9.22 #\n",
      "# T loss -       5.36 | V loss -      12.06 #\n",
      "# T acc  -       0.80 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -         14 | time(s) -      9.10 #\n",
      "# T loss -       5.15 | V loss -      12.17 #\n",
      "# T acc  -       0.81 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -         15 | time(s) -      9.09 #\n",
      "# T loss -       4.94 | V loss -      12.30 #\n",
      "# T acc  -       0.82 | V acc  -       0.54 #\n",
      "#############################################\n",
      "# epoch  -         16 | time(s) -      9.16 #\n",
      "# T loss -       4.77 | V loss -      12.20 #\n",
      "# T acc  -       0.83 | V acc  -       0.55 #\n",
      "#############################################\n",
      "# epoch  -         17 | time(s) -      9.06 #\n",
      "# T loss -       4.60 | V loss -      12.18 #\n",
      "# T acc  -       0.83 | V acc  -       0.56 #\n",
      "#############################################\n",
      "# epoch  -         18 | time(s) -      9.12 #\n",
      "# T loss -       4.46 | V loss -      12.21 #\n",
      "# T acc  -       0.85 | V acc  -       0.56 #\n",
      "#############################################\n",
      "# epoch  -         19 | time(s) -      8.96 #\n",
      "# T loss -       4.32 | V loss -      12.15 #\n",
      "# T acc  -       0.85 | V acc  -       0.57 #\n",
      "#############################################\n"
     ]
    }
   ],
   "source": [
    "model_v1 = Model_V3(window_size, hanning_window)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('using cuda')\n",
    "    model_v1.cuda()\n",
    "\n",
    "criterion = nn.BCELoss(size_average=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_v1.parameters(), lr=learning_rate)\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "# i, ((data, cent), v_l) = next(enumerate(test_loader))\n",
    "losses = []\n",
    "v_losses = []\n",
    "accuracy = []\n",
    "v_accuracy = []\n",
    "l = None\n",
    "for epoch in range(20):\n",
    "    loss_t = 0.0\n",
    "    acc_t = 0.0\n",
    "    count_t = 0\n",
    "    start_time = time.time()\n",
    "    val_l = None\n",
    "    v_out = None\n",
    "    v_all = []\n",
    "    for c, ((all_data, windexes), labels) in enumerate(train_loaders):\n",
    "        for i, win in enumerate(windexes.numpy()[0]):\n",
    "            inp_subs = Variable(to_spectogram(all_data[:,win*window_size:(win+1)*window_size,]))\n",
    "            l = None\n",
    "            l = labels[0, i].type(torch.FloatTensor)\n",
    "            if torch.cuda.is_available():\n",
    "                l = l.cuda()\n",
    "            l = Variable(l)\n",
    "            output = model_v1(inp_subs)\n",
    "#             print(output)\n",
    "            loss = criterion(output, l)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_t += loss.data[0]\n",
    "            \n",
    "            comparison = (output.cpu().data.numpy().ravel() > 0.5) == (l.cpu().data.numpy())\n",
    "            acc_t += comparison.sum() / (window_size//hanning_window)\n",
    "            \n",
    "            count_t += 1\n",
    "\n",
    "    losses.append(loss_t/count_t)\n",
    "    accuracy.append(acc_t/count_t)\n",
    "    \n",
    "    loss_v = 0.0\n",
    "    acc_v = 0.0\n",
    "    count_v = 0\n",
    "    for c, ((data, windexes), v_l) in enumerate(test_loader):\n",
    "        for i, win in enumerate(windexes.numpy()[0]):\n",
    "            inp_subs = Variable(to_spectogram(data[:,win*window_size:(win+1)*window_size,]))\n",
    "            l = None\n",
    "            l = v_l[0, i].type(torch.FloatTensor)\n",
    "            if torch.cuda.is_available():\n",
    "                l = l.cuda()\n",
    "            l = Variable(l)\n",
    "            output = model_v1(inp_subs)\n",
    "            loss = criterion(output, l)\n",
    "\n",
    "            loss_v += loss.data[0]\n",
    "            count_v += 1\n",
    "            \n",
    "            comparison = (output.cpu().data.numpy().ravel() > 0.5) == (l.cpu().data.numpy())\n",
    "            acc_v += comparison.sum() / (window_size//hanning_window)\n",
    "            \n",
    "    v_losses.append(loss_v/count_v)\n",
    "    v_accuracy.append(acc_v/count_v)\n",
    "    print('#'*45)\n",
    "    print('# epoch  - {:>10} | time(s) -{:>10.2f} #'.format(epoch, time.time() - start_time))\n",
    "    print('# T loss - {:>10.2f} | V loss - {:>10.2f} #'.format(loss_t/count_t, loss_v/count_v))\n",
    "    print('# T acc  - {:>10.2f} | V acc  - {:>10.2f} #'.format(acc_t/count_t, acc_v/count_v))\n",
    "print('#'*45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of range for dimension 1 (of size 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-8dc1c7fe6840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     for i in range((data.size()[1]//window_size)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0minp_subs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_spectogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_subs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout_for_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_for_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-1c80a62f5516>\u001b[0m in \u001b[0;36mto_spectogram\u001b[0;34m(matrix)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mspectograms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         f, t, Sxx = signal.spectrogram(matrix[0,:,i].numpy(), \n\u001b[0m\u001b[1;32m     14\u001b[0m                            \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hann'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhanning_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                            \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of range for dimension 1 (of size 1)"
     ]
    }
   ],
   "source": [
    "v_dataset = SleepDatasetValid('/beegfs/ga4493/projects/groupb/data/training/RECORDS', \n",
    "                                '/beegfs/ga4493/projects/groupb/data/training/', 20, 21, window_size, hanning_window)\n",
    "\n",
    "v_loader = torch.utils.data.DataLoader(dataset=v_dataset, \n",
    "                                          batch_size=1, \n",
    "                                          shuffle=False)\n",
    "start = 0\n",
    "stop = 2000000\n",
    "ones = np.ones(hanning_window)\n",
    "# plt.plot(all_data.cpu().view(-1).numpy())\n",
    "# plt.show()\n",
    "\n",
    "for c, ((data, windexes), v_l) in enumerate(v_loader):\n",
    "    out_for_plot = []\n",
    "#     for i in range((data.size()[1]//window_size)):\n",
    "    for i in range((start//window_size), (stop//window_size)):\n",
    "        inp_subs = Variable(to_spectogram(data[:,i*window_size:(i+1)*window_size,]))\n",
    "        output = model_v1(inp_subs).cpu().data.numpy()\n",
    "        out_for_plot = np.append(out_for_plot, output)\n",
    "    out_for_plot = np.repeat(out_for_plot, hanning_window)\n",
    "    f = plt.figure(figsize=(20, 10))\n",
    "    plt.plot(out_for_plot)\n",
    "#     plt.plot((v_l.numpy()[0][:len(v_l.numpy()[0])] > 0).astype(float)*1.1, alpha=0.3)\n",
    "#     plt.plot((v_l.numpy()[0][:len(v_l.numpy()[0])] < 0).astype(float)*1.1, alpha=0.3)\n",
    "    plt.plot((v_l.numpy()[0][(start): (stop)] > 0).astype(float)*1.1, alpha=0.3)\n",
    "    plt.plot((v_l.numpy()[0][(start): (stop)] < 0).astype(float)*1.1, alpha=0.3)\n",
    "    plt.ylim((0,1.15))\n",
    "    plt.axhline(y=0.5, color='r', linestyle='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2af29fa961d0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inp_subs.cpu().squeeze(0).squeeze(0).data.numpy(), aspect='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.2996e+00  1.6260e+00  3.0259e-01  ...   9.3928e-01  1.8561e+00  2.7188e+00\n",
       " 4.3400e+00  4.0113e+00  2.2069e+00  ...   3.1916e+00  4.3439e+00  4.6976e+00\n",
       " 9.6335e+00  1.1000e+01  3.1553e+00  ...   5.9800e+00  6.7392e+00  4.8660e+00\n",
       "                ...                   â‹±                   ...                \n",
       "-3.2710e-01 -3.4102e-01 -3.4611e-01  ...  -3.4101e-01 -3.4745e-01 -3.3926e-01\n",
       "-3.3730e-01 -3.4784e-01 -3.4394e-01  ...  -3.2754e-01 -3.3018e-01 -3.4452e-01\n",
       "-3.5108e-01 -3.4766e-01 -3.3660e-01  ...  -3.0587e-01 -3.2258e-01 -3.3876e-01\n",
       "[torch.FloatTensor of size 1025x12]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_subs.cpu().squeeze(0).squeeze(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
